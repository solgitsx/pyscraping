{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7장 셀레니움을 이용한 웹 스크레이핑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 셀레니움 소개 및 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 셀레니움으로 웹 브라우저 제어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 웹 사이트 접속"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 285페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "\n",
    "driver = Chrome()                   # 크롬 드라이버 객체 생성\n",
    "\n",
    "driver.set_window_size(800, 600)    # 웹 브라우저의 창 크기 설정\n",
    "# driver.maximize_window()        \n",
    "\n",
    "driver.get(\"https://www.google.com\") # 웹 브라우저를 실행해 지정한 URL에 접속\n",
    "\n",
    "print(\"- 접속한 웹 사이트의 제목:\", driver.title)       # 접속한 웹 사이트의 제목 출력\n",
    "print(\"- 접속한 웹 사이트의 URL:\", driver.current_url)  # 접속한 웹 사이트의 URL 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2 HTML 코드에서 요소 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3 검색창에 문자열 입력하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 289페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = Chrome()                # 크롬 드라이버 객체 생성\n",
    "driver.set_window_size(800, 800) # 웹 브라우저의 창 크기 설정      \n",
    "\n",
    "url = \"https://www.google.com\"   # URL 지정\n",
    "driver.get(url)                  # 웹 브라우저를 실행해 지정한 URL에 접속\n",
    "\n",
    "query = \"python\"\n",
    "input_element = driver.find_element(By.NAME, \"q\") # 검색어를 입력할 수 있는 검색창 찾기\n",
    "input_element.send_keys(query)                    # 검색창에 검색어 입력 \n",
    "input_element.submit()                            # 검색 결과 요청\n",
    "\n",
    "print(\"- 접속한 웹 사이트의 제목:\", driver.title) # 접속한 웹 사이트의 제목 출력\n",
    "print(\"- 접속한 웹 사이트의 URL:\", driver.current_url) # 접속한 웹 사이트의 URL 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 291페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "\n",
    "driver = Chrome()                # 크롬 드라이버 객체 생성\n",
    "driver.set_window_size(800, 800) # 웹 브라우저의 창 크기 설정      \n",
    "\n",
    "url = \"https://www.naver.com\"    # URL 지정\n",
    "driver.get(url)  # 웹 브라우저를 실행해 지정한 URL에 접속\n",
    "\n",
    "query = \"파이썬\"\n",
    "\n",
    "# 검색어를 입력할 수 있는 검색창의 찾기\n",
    "input_element = driver.find_element(By.NAME, \"query\")   \n",
    "input_element.send_keys(query)   # 검색창에 검색어 입력 \n",
    "input_element.submit()           # 검색 결과 요청\n",
    "\n",
    "print(\"- 접속한 웹 사이트의 제목:\", driver.title) # 접속한 URL의 제목 출력\n",
    "print(\"- 접속한 웹 사이트의 URL:\", driver.current_url)  # 접속한 URL 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.4 웹 사이트 로그인 자동화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 295페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver = Chrome()                  # 크롬 드라이버 객체 생성    \n",
    "driver.set_window_size(800, 900)   # 웹 브라우저의 창 크기 설정\n",
    "\n",
    "url = \"https://accounts.kakao.com\" # 카카오 계정 로그인 URL 지정\n",
    "driver.get(url)                    # 웹 브라우저를 실행해 지정한 URL에 접속\n",
    "\n",
    "my_id = \"kakao_id\"                 # 자신의 아이디 입력\n",
    "my_pw = \"kakao_password\"           # 자신의 패스워드 입력\n",
    "\n",
    "# 아이디 입력\n",
    "# user_id = driver.find_element(By.ID, \"id_email_2\")    # id 속성으로 아이디(ID) 입력창 찾기 \n",
    "user_id = driver.find_element(By.NAME, \"email\")         # name 속성으로 아이디(ID) 입력창 찾기\n",
    "user_id.send_keys(my_id)                                # 아이디 전송\n",
    "\n",
    "# 패스워드 입력\n",
    "# user_pw = driver.find_element(By.ID, \"id_password_3\") # id 속성으로 패스워드(비밀번호) 입력창 찾기 \n",
    "user_pw = driver.find_element(By.NAME, \"password\")      # name 속성으로 패스워드(비밀번호) 입력창 찾기\n",
    "user_pw.send_keys(my_pw)                                # 패스워드 전송\n",
    "time.sleep(1)\n",
    "\n",
    "# 로그인 버튼 클릭하기 \n",
    "xpath = '//*[@id=\"login-form\"]/fieldset/div[8]/button[1]' # XPath\n",
    "login_button = driver.find_element(By.XPATH, xpath)       # XPath로 로그인 버튼 찾기\n",
    "login_button.click()                                      # 버튼 클릭\n",
    "    \n",
    "print(\"- 접속한 웹 사이트의 제목:\", driver.title)       # 접속한 URL의 제목 출력\n",
    "print(\"- 접속한 웹 사이트의 URL:\", driver.current_url)  # 접속한 URL 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 297페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver = Chrome()                # 크롬 드라이버 객체 생성\n",
    "driver.set_window_size(800, 900) # 웹 브라우저의 창 크기 설정\n",
    "\n",
    "url = \"https://nid.naver.com/\"   # 네이버 계정 로그인 URL 지정\n",
    "driver.get(url)                  # 웹 브라우저를 실행해 지정한 URL에 접속\n",
    "\n",
    "my_id = \"naver_id\"               # 자신의 아이디 입력\n",
    "my_pw = \"naver_password\"         # 자신의 패스워드 입력\n",
    "\n",
    "# 아이디 입력\n",
    "script_id = f\"document.getElementsByName('id')[0].value='{my_id}'\"\n",
    "driver.execute_script(script_id)  # 자바스크립트로 아이디 입력\n",
    "\n",
    "# 패스워드 입력\n",
    "script_pw = f\"document.getElementsByName('pw')[0].value='{my_pw}'\"\n",
    "driver.execute_script(script_pw)  # 자바스크립트로 패스워드 입력\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# 로그인 버튼 클릭하기 \n",
    "xpath = '//*[@id=\"log.login\"]'                     # XPath\n",
    "login_button = driver.find_element(By.XPATH, xpath)# XPath로 로그인 버튼 찾기\n",
    "login_button.click()                               # 버튼 클릭\n",
    "    \n",
    "print(\"- 접속한 웹 사이트의 제목:\", driver.title)  # 접속한 URL의 제목 출력\n",
    "print(\"- 접속한 웹 사이트의 URL:\", driver.current_url) # 접속한 URL 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.5 웹 브라우저 스크롤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 299페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver = Chrome()                  # 크롬 드라이버 객체 생성\n",
    "driver.set_window_size(1000, 1000) # 웹 브라우저의 창 크기 설정\n",
    "\n",
    "url = \"https://www.google.com\"     # URL 지정\n",
    "driver.get(url)                    # 웹 브라우저를 실행해 지정한 URL에 접속\n",
    "\n",
    "input_element = driver.find_element(By.NAME, \"q\") # 검색창 찾기\n",
    "input_element.clear()              # 검색창 내용 모두 지우기\n",
    "query = \"python\"\n",
    "input_element.send_keys(query)     # 검색창에 검색어 입력\n",
    "input_element.submit()             # 검색 결과 요청\n",
    "\n",
    "# 웹 사이트 문서 높이 가져오기\n",
    "scroll_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "print(\"- 웹 사이트 문서 높이:\", scroll_height)\n",
    "\n",
    "y = 0         # Y축 좌표의 초깃값\n",
    "y_step = 200  # Y축 아래로 이동하는 단계\n",
    "\n",
    "while (True):\n",
    "    y = y + y_step\n",
    "    script =  \"window.scrollTo(0,{0})\".format(y)\n",
    "    driver.execute_script(script)   # 스크립트 실행\n",
    "    time.sleep(1)                   # 데이터를 받아올 때까지 기다림\n",
    "    \n",
    "    # 수식 스크롤 위치가 문서 끝보다 크거나 같으면 while 문 빠져나가기\n",
    "    if (y >= scroll_height):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.6 웹 브라우저 내용을 이미지 파일로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 300페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver = Chrome()                # 크롬 드라이버 객체 생성\n",
    "driver.set_window_size(800, 780) # 웹 브라우저의 창 크기 설정\n",
    "\n",
    "url = \"https://www.google.com\"   # URL 지정\n",
    "driver.get(url)                  # 웹 브라우저를 실행해 지정한 URL에 접속\n",
    "\n",
    "input_element = driver.find_element(By.NAME, \"q\") # 검색창 찾기\n",
    "input_element.clear()                   # 검색창 내용 모두 지우기\n",
    "query = \"환율\"\n",
    "input_element.send_keys(query)         # 검색창에 검색어 입력\n",
    "input_element.submit()                 # 검색 결과 요청\n",
    "\n",
    "folder = \"C:/myPyScraping/data/ch07/\" # 폴더 지정\n",
    "image_file = folder + \"환율정보.png\"  # 생성할 이미지 파일 이름 지정\n",
    "driver.save_screenshot(image_file)    # 웹 브라우저 내용을 캡처해 이미지 파일로 저장\n",
    "\n",
    "time.sleep(3) \n",
    "driver.quit()  # 웹 브라우저를 종료함\n",
    "\n",
    "print(\"- 생성한 이미지 파일:\", image_file) # 접속한 URL의 제목 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 301페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = Chrome()                # 크롬 드라이버 객체 생성\n",
    "driver.set_window_size(800, 780) # 웹 브라우저의 창 크기 설정\n",
    "driver.get(image_file)           # 웹 브라우저로 이미지 파일 열기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.7 헤드리스(Headless) 웹 브라우저 이용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 303페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options()                  # 옵션 설정을 위한 객체 생성\n",
    "options.add_argument('headless')     # 헤드리스 웹 브라우저로 옵션 설정\n",
    "options.add_argument('window-size=1100,1000') # 웹 브라우저의 창 크기 설정\n",
    "\n",
    "driver = Chrome(options=options)     # 옵션을 지정해 크롬 드라이버의 객체 생성\n",
    "\n",
    "url = \"https://finance.naver.com/\"   # URL 지정\n",
    "driver.get(url)                      # 웹 브라우저를 실행해 지정한 URL에 접속\n",
    "driver.implicitly_wait(3)            # 웹 사이트의 내용을 받아오기까지 기다림\n",
    "\n",
    "folder = \"C:/myPyScraping/data/ch07/\"   # 폴더 지정\n",
    "image_file = folder + \"네이버_금융.png\" # 생성할 이미지 파일 이름 지정\n",
    "driver.save_screenshot(image_file)      # 웹 브라우저 내용을 캡처해 이미지 파일로 저장\n",
    "\n",
    "driver.quit() # 웹 브라우저 종료\n",
    "\n",
    "print(\"- 생성한 이미지 파일:\", image_file) # 접속한 URL의 제목 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 304페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(filename=image_file)              # 이미지 파일 이름을 지정\n",
    "# Image(filename=image_file, width=800) # 이미지 파일 이름과 너비를 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 동적 웹 페이지에서 데이터 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.1 커피 전문점 음료 메뉴 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 306페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "url = \"https://www.starbucks.co.kr/menu/drink_list.do\"\n",
    "\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "# 요소 검사를 수행한 결과의 상위 태그와 속성을 이용\n",
    "products = soup.select('li.menuDataSet dl dd') \n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 307페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "products = soup.select('div.product_list dl dd')\n",
    "products[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 308페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "driver = Chrome() # 옵션을 지정해 크롬 드라이버의 객체 생성\n",
    "\n",
    "url = \"https://www.starbucks.co.kr/menu/drink_list.do\" # URL 지정\n",
    "driver.get(url)                    # 웹 브라우저를 실행해 지정한 URL에 접속\n",
    "driver.implicitly_wait(3)          # 웹 사이트의 내용을 받아오기까지 기다림\n",
    "\n",
    "html = driver.page_source          # 접속 후에 해당 page의 HTML 코드를 가져옴\n",
    "soup = BeautifulSoup(html, 'lxml') # HTML 코드를 파싱함\n",
    "\n",
    "print(\"- 접속한 웹 사이트의 제목:\", driver.title) # 접속한 웹 사이트의 제목 출력\n",
    "print(\"- 접속한 웹 사이트의 URL:\", driver.current_url) # 접속한 웹 사이트의 URL 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drink_products = soup.select('div.product_list dl dd ul li.menuDataSet dl')\n",
    "drink_products[0] # 첫 번째 음료 메뉴의 요소 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 309페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(drink_products[0].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drink_menu_name = drink_products[0].select_one('dd').get_text()\n",
    "drink_menu_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 310페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drink_menu_photo_link = drink_products[0].select_one('a img')['src']\n",
    "drink_menu_photo_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver import Chrome\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "\n",
    "options = Options()\n",
    "options.headless = True # 헤드리스 모드로 지정해 크롬을 GUI 없이 수행\n",
    "\n",
    "driver = Chrome(options=options) # 옵션을 지정해 크롬 드라이버의 객체 생성\n",
    "\n",
    "url = \"https://www.starbucks.co.kr/menu/drink_list.do\"  # URL 지정\n",
    "driver.get(url)              # 웹 브라우저를 실행해 지정한 URL에 접속\n",
    "driver.implicitly_wait(3)    # 웹 사이트의 내용을 받아오기까지 기다림\n",
    "\n",
    "html = driver.page_source    # 접속 후에 해당 page의 HTML 코드를 가져옴\n",
    "soup = BeautifulSoup(html, 'lxml') # HTML 코드 파싱\n",
    "\n",
    "drink_products = soup.select('div.product_list dl dd ul li.menuDataSet dl')\n",
    "driver.quit() # 웹 브라우저를 종료함\n",
    "\n",
    "drink_menu_name_photo_links = [] \n",
    "for drink_product in drink_products:\n",
    "    menu_name = drink_product.select_one('dd').get_text()\n",
    "    menu_photo_link = drink_product.select_one('a img')['src']\n",
    "    drink_menu_name_photo_links.append((menu_name, menu_photo_link))\n",
    "\n",
    "drink_menu_name_photo_links[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 311페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(drink_menu_name_photo_links) # 스타벅스 음료 메뉴의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_drink_menu = [\"메뉴\", \"사진\"]\n",
    "df = pd.DataFrame(drink_menu_name_photo_links, columns=col_drink_menu)\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지의 링크를 HTML img 태그로 만드는 함수 \n",
    "def make_HTML_image_tag(link):\n",
    "    image_width = 80   # 이미지 크기(너비)를 지정\n",
    "    image_tag = f'<img src=\"{link}\" width=\"{image_width}\">' # img 태그\n",
    "    return image_tag  # img 태그를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_HTML_image_tag(df[\"사진\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 313페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_table = df.head(4).to_html(formatters=dict(사진=make_HTML_image_tag), escape=False)\n",
    "print(html_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 314페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(html_table) # HTML 코드의 내용을 웹 브라우저처럼 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 315페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"C:/myPyScraping/data/ch07/\"            # 폴더 지정\n",
    "file_name = folder + \"starbucks_drink_menu.html\" # 생성할 HTML 파일 이름 지정 \n",
    "\n",
    "df.to_html(file_name, formatters=dict(사진=make_HTML_image_tag), escape=False)\n",
    "\n",
    "print(\"생성한 파일:\", file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2 가상 화폐 거래 정보 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 317페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = \"http://coinmarketcap.com/ko/\" # URL 지정\n",
    "html = requests.get(url).text        # HTML 소스 가져오기\n",
    "dfs = pd.read_html(html)             # HTML 소스에서 table의 내용을 DataFrame 리스트로 변환\n",
    "\n",
    "df = dfs[0]       # 리스트의 첫 번째 요소를 선택\n",
    "df.iloc[0:12,1:6] # DataFrame 데이터에서 행과 열을 선택해 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "driver = Chrome()          # 크롬 드라이버 객체 생성\n",
    "\n",
    "url = \"https://coinmarketcap.com/ko/\" # URL 지정\n",
    "driver.get(url)            # 웹 브라우저를 실행해 지정한 URL에 접속\n",
    "driver.implicitly_wait(3)  # 웹 사이트의 내용을 받아오기까지 기다림\n",
    "\n",
    "html = driver.page_source  # 접속 후에 해당 page의 HTML 소스를 가져옴\n",
    "dfs = pd.read_html(html)   # HTML 소스에서 table의 내용을 DataFrame 리스트로 변환\n",
    "\n",
    "df = dfs[0]       # 리스트의 첫 번째 요소를 선택\n",
    "df.iloc[0:16,1:6] # DataFrame 데이터에서 행과 열을 선택해 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 319페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "driver = Chrome() # 크롬 드라이버 객체 생성\n",
    "\n",
    "url = \"https://coinmarketcap.com/ko/\" # URL 지정\n",
    "driver.get(url)  # 웹 브라우저를 실행해 지정한 URL에 접속\n",
    "\n",
    "# 웹 사이트 문서 높이 가져오기\n",
    "scroll_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "y = 0          # Y축 좌표의 초깃값\n",
    "y_step = 1000  # Y축 아래로 이동하는 단계\n",
    "while (True):\n",
    "    y = y + y_step\n",
    "    script =  \"window.scrollTo(0,{0})\".format(y)\n",
    "    driver.execute_script(script) # 스크립트 실행\n",
    "    driver.implicitly_wait(5)     # 스크롤 수행 후 데이터를 받아올 때까지 기다림\n",
    "    \n",
    "    # 수식 스크롤 위치가 문서 끝보다 크거나 같으면 while 문 빠져나가기\n",
    "    if (y >= scroll_height):\n",
    "        break\n",
    "    \n",
    "html = driver.page_source # HTML 코드를 가져옴\n",
    "dfs = pd.read_html(html)  # HTML 소스에서 table의 내용을 DataFrame 리스트로 변환\n",
    "\n",
    "df = dfs[0]         # 리스트의 첫 번째 요소를 선택\n",
    "df.iloc[95:100,1:6] # DataFrame 데이터에서 행과 열을 선택해 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 320페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:5,1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['이름'] = [name.replace(str(num), \" \") for num, name in zip(df['#'], df['이름'])]\n",
    "df['이름'] = [name.replace(\"구매하기\", \"\") for name in df['이름']]\n",
    "df.iloc[0:5,1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 321페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_coin_info(page_num):\n",
    "    driver = Chrome() # 크롬 드라이버 객체 생성\n",
    "    \n",
    "    # page 추가해 URL 지정\n",
    "    url = f\"https://coinmarketcap.com/ko/?page={page_num}\"\n",
    "    driver.get(url)  # 웹 브라우저를 실행해 지정한 URL에 접속\n",
    "\n",
    "    # 웹 사이트 문서 높이 가져오기\n",
    "    scroll_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    y = 0           # Y축 좌표의 초깃값\n",
    "    y_step = 1000   # Y축 아래로 이동하는 단계\n",
    "    while (True):\n",
    "        y = y + y_step\n",
    "        script =  \"window.scrollTo(0,{0})\".format(y)\n",
    "        driver.execute_script(script) # 스크립트 실행\n",
    "        driver.implicitly_wait(5) # 스크롤 수행 후 데이터를 받아올 때까지 기다림\n",
    "\n",
    "        # 수식 스크롤 위치가 문서 끝보다 크거나 같으면 while 문 빠져나가기\n",
    "        if (y >= scroll_height):\n",
    "            break\n",
    "\n",
    "    html = driver.page_source # HTML 코드를 가져옴\n",
    "    dfs = pd.read_html(html)  # HTML 소스에서 table의 내용을 DataFrame 리스트로 변환\n",
    "\n",
    "    df = dfs[0] # 리스트의 첫 번째 요소를 선택\n",
    "    \n",
    "    # '이름' 열의 내용 변경\n",
    "    df['이름'] = [name.replace(str(num), \" \") for num, name in zip(df['#'], df['이름'])]\n",
    "    df['이름'] = [name.replace(\"구매하기\", \"\") for name in df['이름']]\n",
    "    \n",
    "    driver.quit() # 웹 브라우저를 종료함\n",
    "\n",
    "    return df.iloc[:,1:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 322페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_num = 1 # page 지정\n",
    "df_coin = get_coin_info(page_num) # 함수 호출\n",
    "\n",
    "# DataFrame 데이터에서 행과 열을 선택해 출력\n",
    "with pd.option_context('display.max_rows',6):\n",
    "    pd.set_option(\"show_dimensions\", False) # DataFrame의 행과 열 개수 출력 안 하기\n",
    "    display(df_coin.iloc[:,0:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.3 유튜브 검색 결과 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 324페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "driver = Chrome() # 크롬 드라이버 객체 생성\n",
    "\n",
    "base_url = \"https://www.youtube.com\" # 유튜브의 기본 URL\n",
    "search_word = '/results?search_query=' + '방탄소년단' # 검색어\n",
    "url = base_url +  search_word        # 접속하고자 하는 웹 사이트\n",
    "\n",
    "driver.get(url) # 웹 브라우저를 실행해 지정한 URL에 접속\n",
    "time.sleep(3)   # 웹 브라우저를 실행하고 URL에 접속할 때까지 기다림\n",
    "\n",
    "print(\"- 접속한 웹 사이트의 제목:\", driver.title) # 접속한 웹 사이트의 제목 출력\n",
    "print(\"- 접속한 웹 사이트의 URL:\", driver.current_url) # 접속한 웹 사이트의 URL 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = Chrome()\n",
    "\n",
    "base_url = \"https://www.youtube.com\"\n",
    "search_word = '/results?search_query=' + '방탄소년단'\n",
    "search_option = \"&sp=CAMSAhAB\" # 조회수로 정렬\n",
    "\n",
    "url = base_url +  search_word + search_option # 접속하고자 하는 웹 사이트\n",
    "driver.get(url)\n",
    "time.sleep(3) # 웹 브라우저를 실행하고 URL에 접속할 때까지 기다림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 326페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = driver.page_source # 접속 후에 해당 page의 HTML 코드를 가져옴\n",
    "# driver.quit() # 웹 브라우저를 종료함\n",
    "\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "title_hrefs = soup.select('a#video-title')\n",
    "\n",
    "title_hrefs[0] # 첫 번째 항목 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_hrefs[0].get('title') # title_hrefs[0]['title'] 도 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_hrefs[0]['href'] # title_hrefs[0].get('href')도 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 327페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_url = \"https://www.youtube.com\"\n",
    "titles = []\n",
    "urls = []\n",
    "for title_href in title_hrefs[0:5]:\n",
    "    title = title_href['title']         # 태그 안에서 title 속성의 값을 가져오기\n",
    "    url = base_url + title_href['href'] # href 속성의 값 가져와 기본 url과 합치기\n",
    "    titles.append(title)\n",
    "    urls.append(url)\n",
    "    print(\"{0}, {1}\".format(title, url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 328페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_uploads = soup.select('span.style-scope.ytd-video-meta-block')\n",
    "\n",
    "view_uploads[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 329페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_numbers = view_uploads[0::2] # 인덱스가 짝수인 요소 선택\n",
    "upload_times = view_uploads[1::2] # 인덱스가 홀수인 요소 선택\n",
    "\n",
    "[view_numbers[0:3], upload_times[0:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[view_numbers[0].get_text(), upload_times[0].get_text()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[view_numbers[0].get_text().split(\" \")[-1], upload_times[0].get_text()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 330페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def get_data_from_youtube(word, scroll=False):\n",
    "    driver = Chrome()\n",
    "\n",
    "    base_url = \"https://www.youtube.com\"\n",
    "    search_word = '/results?search_query=' + word\n",
    "    search_option = \"&sp=CAMSAhAB\" # 조회수로 정렬\n",
    "\n",
    "    url = base_url +  search_word + search_option # 접속하고자 하는 웹 사이트\n",
    "    driver.get(url) # URL에 접속\n",
    "    time.sleep(3) # 웹 브라우저를 실행하고 URL에 접속할 때까지 기다림  \n",
    "    \n",
    "    if(scroll==True):\n",
    "        # 수직(Y축 방향)으로 스크롤 동작하기 \n",
    "        y = 0 # Y축 방향으로 스크롤 이동할 거리 초기화\n",
    "        y_step = 1000\n",
    "        for k in range(1, 5): # 반복 횟수 지정\n",
    "            y = y + y_step  # 반복할 때마다 Y축 방향으로 더해지는 거리를 지정\n",
    "            script = \"window.scrollTo({0},{1})\".format(0, y)\n",
    "            driver.execute_script(script) # Y축 방향으로 스크롤\n",
    "            time.sleep(3) # 결과를 받아올 때까지 잠시 기다림\n",
    "\n",
    "    html = driver.page_source # 접속 후에 해당 page의 HTML 코드를 가져옴\n",
    "    # driver.quit() # 웹 브라우저를 종료함\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    # 동영상 제목과 URL 추출하기\n",
    "    title_hrefs = soup.select('a#video-title')\n",
    "    \n",
    "    titles = []\n",
    "    urls = []    \n",
    "    for title_href in title_hrefs:\n",
    "        title = title_href['title']         # 태그 안에서 title 속성의 값을 가져오기\n",
    "        url = base_url + title_href['href'] # href 속성의 값 가져와 기본 url과 합치기        \n",
    "        titles.append(title)\n",
    "        urls.append(url)\n",
    "\n",
    "    # 조회수와 업로드 시기 추출하기\n",
    "    view_uploads = soup.select('span.style-scope.ytd-video-meta-block')\n",
    "    \n",
    "    view_numbers = view_uploads[0::2] # 인덱스가 짝수인 요소 선택\n",
    "    upload_times = view_uploads[1::2] # 인덱스가 홀수인 요소 선택\n",
    "\n",
    "    views = []\n",
    "    uploads = [] \n",
    "    for view_number, upload_time in zip(view_numbers, upload_times):\n",
    "        view = view_number.get_text().split(\" \")[-1] # 조회수 추출\n",
    "        upload = upload_time.get_text()              # 업로드 시기 추출\n",
    "        views.append(view)\n",
    "        uploads.append(upload)\n",
    "        \n",
    "    # 추출된 정보를 모으기\n",
    "    search_results = []\n",
    "    for title, url, view, upload in zip(titles, urls, views, uploads):\n",
    "        search_result = [title, url, view, upload]\n",
    "        search_results.append(search_result)\n",
    "    \n",
    "    # 추출 결과를 판다스 DataFrame 데이터 형식으로 변환\n",
    "    df = pd.DataFrame(search_results, columns=[\"제목\", \"링크\", \"조회수\", \"업로드\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 331페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data_from_youtube('방탄소년단') # get_data_from_youtube('방탄소년단', False) 도 가능\n",
    "df.tail()\n",
    "# df # 전체를 다 출력하려면 df.tail() 대신 df를 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7장: 333페이지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = get_data_from_youtube('방탄소년단', True)\n",
    "df.tail() # 전체 중 끝 부분만 확인\n",
    "# df # 전체를 다 출력하려면 df.tail() 대신 df를 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 정리"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": "7",
   "nav_menu": {
    "height": "400px",
    "width": "252px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "545px",
    "left": "46px",
    "right": "1154px",
    "top": "142.133px",
    "width": "333px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc_position": {
   "height": "503px",
   "left": "0px",
   "right": "952.167px",
   "top": "107px",
   "width": "300px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
